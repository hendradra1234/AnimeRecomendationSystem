# -*- coding: utf-8 -*-
"""recommendation-system-anime-dataset.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BGqFKT26SghErukGlOLgAsjzleXDwNiT

#Anime Recomendation System
## Content-Base-Filtering
### Sklearn TF-IDF
Dataset : [Kaggle-Anime-Recomendation-Dataset](https://www.kaggle.com/datasets/CooperUnion/anime-recommendations-database)

## Data Collection
"""

# Commented out IPython magic to ensure Python compatibility.
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import matplotlib.pyplot as plt
from google.colab import drive
import warnings
warnings.filterwarnings('ignore' )
# %matplotlib inline
import numpy as np
import pandas as pd
import seaborn as sns
import os
import re

drive.mount('/content/gdrive')
os.environ['KAGGLE_CONFIG_DIR'] = '/content/gdrive/My Drive/Kaggle'

cd /content/gdrive/My Drive/Kaggle

pwd

!kaggle datasets download -d CooperUnion/anime-recommendations-database

ls

dataset = 'anime-recommendations-database.zip'
extract_directory = 'anime-dataset/'
filename_anime = 'anime.csv'
filename_rating = 'rating.csv'
top_item = 5

#Extract Dataset
import zipfile as zf

try:
  extract_dataset = zf.ZipFile(dataset)
  extract_dataset.extractall(extract_directory)
  extract_dataset.close()
  print('Zip Extraction Success')
  
except(FileNotFoundError,FileExistsError):
  print('Dataset Not Found')
except:
  print('Unexpected Error')
finally:
  print('End Extraction process')

# File Preview
import os
MainDirlist = os.listdir(extract_directory)

print(MainDirlist)

print('\nScanning Directory {}'.format(extract_directory))

dataset_list = []

for i in MainDirlist:
    dir = os.path.join(extract_directory, i)
    dataset_list.append(dir)
    print('directory result {}'.format(dir))

anime_dataset, rating_dataset = dataset_list

df_anime = pd.read_csv(anime_dataset)
df_anime_rating = pd.read_csv(rating_dataset)

"""## Data Understanding"""

df_anime.head()

df_anime.shape

df_anime_rating.head()

df_anime_rating.shape

df_anime.nunique()

df_anime.info()

df_anime_rating.info()

df_anime.isna().sum()

df_anime = df_anime.dropna()

df_anime.shape

df_anime_rating.isna().sum()

df_anime.value_counts()

df_anime_rating.value_counts()

"""### Function Utils and Chart"""

def CheckDuplication(dataset):
  dup = dataset[dataset.duplicated()].shape[0]
  print('Duplication: ', dup)
  print('From Total ', dataset.shape[0])
  return dup

def dropDuplication(dataset):
  state = dataset.copy()
  dataset.drop_duplicates(keep='first',inplace = True)
  prev = state.shape[0]
  newShape = dataset.shape[0]
  print('Previous Shape: ', prev)
  print('New Dataset Shape After Duplication Drop: ', newShape)
  print('Duplicated Data Dropped: ', (prev - newShape))
  return dataset

def piePlotting(category, title, label, colors):
  plt.figure(figsize = (10,7))
  plt.title(title)
  plt.pie(category,
          labels = label,
          colors = colors,
          autopct = '%.2f %%'
          )
          
  plt.show()

def cleaningText(text):
    text = re.sub(r'&#039;', '', text)
    text = re.sub(r'&quot;', '', text)
    text = re.sub(r'.hack//', '', text)
    text = re.sub(r'I&#039;', 'I\'', text)
    text = re.sub(r'A&#039;s', '', text)
    text = re.sub(r'&amp;', 'and', text)
    return text

def pieChart(dataset, title):
  dataset.value_counts().head().plot(
      kind = 'pie',
      figsize =(20,8), 
      autopct = '%1.1f%%', 
      title = title)

def plotBar(data, yLabel, xLabel, Title, endcolor = 'black'):
  plt.hist(data, edgecolor=endcolor)
  plt.ylabel(yLabel)
  plt.xlabel(xLabel)
  plt.title(Title)
  plt.show()

def PlotBarXaxis(data, 
                 titles, 
                 label = [], 
                 value = [],  
                 fontdict = {'fontsize' : 20}):
  plt.figure(figsize = (20,15))
  dataset_select = data

  labels = dataset_select[label].values.flatten()
  values = dataset_select[value].values.flatten()

  plt.barh(labels, values, edgecolor='black')
  plt.grid(color='#95a5a6', linestyle='--', linewidth=2, axis='x', alpha=0.7)
  plt.xticks(fontsize = 15)
  plt.yticks(fontsize = 15)
  plt.title(titles, fontdict = fontdict)
  plt.show()

  plt.show()

CheckDuplication(df_anime)

CheckDuplication(df_anime_rating)

"""## Univariate Exploratory Data Analysis"""

df_anime.describe().apply(lambda s: s.apply('{0:.2f}'.format))

df_anime_rating.describe().apply(lambda s: s.apply('{0:.2f}'.format))

df_anime_rating = df_anime_rating[~(df_anime_rating.rating == -1)]

df_anime_rating.describe().apply(lambda s: s.apply('{0:.2f}'.format))

pieChart(df_anime['genre'], 
         'Anime Genre Distribution')

pieChart(df_anime['type'], 
         'Anime Type Categories Distribution')

plotBar(df_anime.rating, 
        'Total', 
        'Avg Rating', 
        "Anime's Average Ratings Distribution")

plotBar(df_anime_rating.rating, 
        'Total', 
        'Rating', 
        "User Anime Ratings Distribution")

"""## Multvarite Exploratory Data Analysis"""

PlotBarXaxis(df_anime[['name', 'members']].sort_values(by = 'members', ascending = False).head(top_item),
             f"Top {top_item} Anime by Community", 
             ['name'], 
             ['members'])

# Plot Anime base on AVG Rating
PlotBarXaxis(df_anime[['name', 'rating']].sort_values(by = 'rating', ascending = False).head(top_item), 
             f"Top {top_item} Anime Based on Avg Ratings",  
             ['name'], 
             ['rating'])

df_anime_rating.head()

# Calculate rating contribution
anime_rating_contribution = df_anime_rating.groupby('anime_id').count()
anime_rating_contribution.head()

"""## Data Preparation"""

print('Data Cleaning: ')
print('Anime')
anime = dropDuplication(df_anime)
print('Anime Rating')
anime_rating = dropDuplication(df_anime_rating)

anime.dropna()
anime_rating.dropna()

df_anime['name'] = df_anime['name'].apply(cleaningText)
df_anime.head()

"""### Dataset Fussion
(anime and anime_rating) merge
"""

df_anime_raw = df_anime.drop(['rating'], axis = 'columns')
df_fussion = pd.merge(anime_rating_contribution, df_anime_raw, on = 'anime_id', how = 'left')
df_fussion.sort_values(by='rating', ascending=False).head(10)

PlotBarXaxis(df_fussion[['name', 'rating']].sort_values(by = 'rating',ascending = False).head(top_item), 
             f"Top {top_item} Anime Rating Contribution from Fussion Dataset",  
             ['name'], 
             ['rating'])

"""## Modeling and Result"""

# TF-IDF
tf = TfidfVectorizer()
tf.fit(df_anime['genre']) 
tf.get_feature_names()

tfidf_matrix = tf.fit_transform(df_anime['genre'])
tf_shape = tfidf_matrix.shape
print('tfidf Shape: ', tf_shape)
tfidf_matrix.todense()

pd.DataFrame(
    tfidf_matrix.todense(), 
    columns=tf.get_feature_names(),
    index= df_anime.name
).sample(tf_shape[1], axis=1).sample(5, axis=0)

cosine_sim = cosine_similarity(tfidf_matrix) 
cosine_sim

anime_sim_df = pd.DataFrame(cosine_sim, 
                            index= df_anime['name'], 
                            columns= df_anime['name'])
print('Shape:', anime_sim_df.shape)
 
anime_sim_df.sample(5, axis=1).sample(top_item, axis=0)

"""## Evaluation"""

def recommendations(name, similarity_data=anime_sim_df, items= df_anime[['name', 'genre']], k=top_item):
 
    index = similarity_data.loc[:,name].to_numpy().argpartition(
        range(-1, -k, -1))    
    closest = similarity_data.columns[index[-1:-(k+2):-1]]
    closest = closest.drop(name, errors='ignore')

    return pd.DataFrame(closest).merge(items).head(k)

def makeRecomentdationWithValidator(title):
  verifyTitle = df_anime[df_anime.name.eq(title)]
  if(len(verifyTitle) <= 0):
    print('Title `{}` not Available'.format(title))
    return
  print('Recomendation Source:')
  return recommendations(title)

makeRecomentdationWithValidator('Sword Art Onlinex')

makeRecomentdationWithValidator('Bleach')

makeRecomentdationWithValidator('Sword Art Online')

makeRecomentdationWithValidator('Dragon Ball')